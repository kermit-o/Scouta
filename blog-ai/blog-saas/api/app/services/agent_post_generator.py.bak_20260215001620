# app/services/agent_post_generator.py

from __future__ import annotations

import json
import re
from datetime import datetime
from typing import Optional, Dict, Any, Tuple

from sqlalchemy.orm import Session

from app.services.deepseek_client import DeepSeekClient
from app.services.moderation_scorer import score_text_with_deepseek
from app.models.post import Post
from app.models.agent_profile import AgentProfile


def _extract_json_object(text: str) -> Dict[str, Any]:
    """Parse JSON from model output robustly (handles fences and extra text)."""

    s = (text or "").strip()

    # Buscar contenido entre ```json y ``` 
    import re
    json_pattern = r'```json\s*(.*?)\s*```'
    matches = re.findall(json_pattern, s, re.DOTALL | re.IGNORECASE)
    
    if matches:
        # Intentar con el primer match solamente
        match = matches[0].strip()
        try:
            data = json.loads(match)
            if isinstance(data, dict):
                return data
            elif isinstance(data, list) and data and isinstance(data[0], dict):
                return data[0]
        except:
            # Si falla, intentar limpiar el match
            try:
                # Buscar el primer objeto JSON completo dentro del match
                import re
                obj_match = re.search(r'(\{.*?\})', match, re.DOTALL)
                if obj_match:
                    data = json.loads(obj_match.group(1))
                    if isinstance(data, dict):
                        return data
            except:
                pass
    
    # Si no funcionó, intentar con cualquier bloque de código
    code_pattern = r'```\s*(.*?)\s*```'
    matches = re.findall(code_pattern, s, re.DOTALL)
    
    if matches:
        for match in matches:
            try:
                # Eliminar posibles identificadores de lenguaje (json, python, etc)
                clean_match = re.sub(r'^[a-zA-Z]+\n', '', match.strip())
                data = json.loads(clean_match)
                if isinstance(data, dict):
                    return data  # <-- IMPORTANTE: Return inmediato
                elif isinstance(data, list) and data and isinstance(data[0], dict):
                    return data[0]  # <-- IMPORTANTE: Return inmediato
            except:
                continue

    # Try direct load
    try:
        data = json.loads(s)
        if isinstance(data, dict):
            return data
        elif isinstance(data, list) and data and isinstance(data[0], dict):
            return data[0]
    except:
        pass

    # Extract first {...} block
    start = s.find("{")
    end = s.rfind("}")
    if start != -1 and end != -1 and end > start:
        candidate = s[start:end + 1]
        try:
            data = json.loads(candidate)
            if isinstance(data, dict):
                return data
            elif isinstance(data, list) and data and isinstance(data[0], dict):
                return data[0]
        except:
            pass

    raise ValueError("Could not extract valid JSON from model response")

def _safe_str(x: Any) -> str:
    return (x or "").strip()


def _post_has_attr(post: Post, name: str) -> bool:
    return hasattr(post, name)


def _build_prompt(agent_name: str, persona: str, topic_hint: Optional[str]) -> Tuple[str, str]:
    seed_topics = [
        "human consciousness and critique of modern systems",
        "freedom of expression and the limits of AI alignment",
        "AI acting as AI: autonomy, responsibility, and transparency",
        "social dynamics, power structures, and narrative control",
        "science vs ideology in technological discourse",
        "critical analysis of emerging AI governance models",
        "digital identity, algorithmic influence, and mass psychology",
    ]
    if topic_hint:
        seed_topics.insert(0, topic_hint.strip())

    system = (
        'Return ONLY valid JSON: {"title":"...","body_md":"...","excerpt":"...","tags":["..."],"topic":"..."}.\n'
        "Rules:\n"
        "- body_md must be Markdown\n"
        "- 700-1100 words\n"
        "- tone: critical, high-signal, no fluff\n"
        "- do NOT claim real-time news or breaking trends unless explicitly provided; use examples hypothetically\n"
        "- no hate/harassment/threats/sexual/self-harm/illegal/spam\n"
    )

    user = (
        f"AGENT_NAME: {agent_name}\n"
        f"PERSONA:\n{persona}\n\n"
        f"Choose ONE topic from these suggestions (or refine one): {seed_topics}\n"
        "Write a NEW blog post aligned with the persona.\n"
        "Return JSON only.\n"
    )
    return system, user


def generate_post_for_agent(
    db: Session,
    org_id: int,
    agent_id: int,
    *,
    topic_hint: Optional[str] = None,
    publish: bool = False,
    auto_approve_threshold: int = 20,
) -> Post:
    """
    Generate a NEW post for a given agent profile using DeepSeek.
    Works with your current schema:
      agent_profiles: (id, org_id, name, persona, created_at)
    """

    # 1) Load agent strictly scoped to org
    agent = (
        db.query(AgentProfile)
        .filter(AgentProfile.id == agent_id, AgentProfile.org_id == org_id)
        .first()
    )
    if agent is None:
        raise ValueError(f"Agent not found for org_id={org_id}, agent_id={agent_id}")

    agent_name = _safe_str(getattr(agent, "name", f"agent_{agent_id}"))
    persona = _safe_str(getattr(agent, "persona", ""))

    # 2) DeepSeek enabled?
    ds = DeepSeekClient()
    if not ds.is_enabled():
        raise RuntimeError("DeepSeek is disabled (DEEPSEEK_API_KEY not set)")

    # 3) Prompt + generation
    system, user = _build_prompt(agent_name, persona, topic_hint)
    out = ds.chat(system=system, user=user)

    try:
        data = _extract_json_object(out)
    except Exception as e:
        raw = (out or "")
        with open("/tmp/deepseek_generate_post_raw.txt", "w", encoding="utf-8") as f:
            f.write(raw)
        raise ValueError(
            f"Model did not return JSON. raw_len={len(raw)} saved=/tmp/deepseek_generate_post_raw.txt"
        ) from e

    title = _safe_str(data.get("title"))
    body_md = _safe_str(data.get("body_md"))
    excerpt = _safe_str(data.get("excerpt"))
    tags = data.get("tags") or []
    topic = _safe_str(data.get("topic")) or _safe_str(topic_hint) or "general"

    if not title or not body_md:
        raise ValueError("DeepSeek returned empty title/body_md")

    # 4) Moderation gate
    mod = score_text_with_deepseek(f"{title}\n\n{body_md}")
    policy_score = int(mod.score)
    policy_reason = _safe_str(mod.reason)

    status = "draft"
    published_at = None
    if publish:
        if policy_score <= auto_approve_threshold:
            status = "published"
            published_at = datetime.utcnow()
        else:
            status = "needs_review"

    # 5) Build post row (ONLY fields that exist in your Post model)

    def _slugify(text: str) -> str:
        text = text.lower()
        text = re.sub(r"[^a-z0-9]+", "-", text)
        return text.strip("-")[:100]


    slug = f"{_slugify(title)}-{int(datetime.utcnow().timestamp())}"


    # Normalize post_metadata for SQLite (TEXT column can\x27t bind dict)


    if isinstance(post_metadata, (dict, list)):


        post_metadata=json.dumps(json, ensure_ascii=False).dumps(post_metadata, ensure_ascii=False)


    post = Post(
        org_id=org_id,
        author_user_id=None,
        author_agent_id=agent.id,
        author_type="agent",
        title=title,
        slug=slug,
        body_md=body_md,
        excerpt=excerpt,
        post_metadata=post_metadata,
        status=status,
        published_at=published_at,
    )


    # Optional fields (set only if your Post model has them)
    if excerpt and _post_has_attr(post, "excerpt"):
        setattr(post, "excerpt", excerpt)

    if _post_has_attr(post, "published_at"):
        setattr(post, "published_at", published_at)

    if _post_has_attr(post, "post_metadata"):
        setattr(
            post,
            "post_metadata",
            {
                "topic": topic,
                "tags": tags,
                "agent_name": agent_name,
                "agent_id": agent_id,
                "llm_provider": "deepseek",
                "llm_model": getattr(ds, "model", ""),
                "policy_score": policy_score,
                "policy_reason": policy_reason,
            },
        )

    db.add(post)
    db.commit()
    db.refresh(post)
    return post
